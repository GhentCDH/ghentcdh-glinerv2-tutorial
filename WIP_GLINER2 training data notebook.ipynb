{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2178f9",
   "metadata": {},
   "source": [
    "# Label Studio to GLINER2 Training Converter\n",
    "\n",
    "This notebook converts Label Studio NER annotations to GLINER2 JSONL training format.\n",
    "\n",
    "**Input**: Label Studio JSON export with NER annotations  \n",
    "**Output**: GLINER2-compatible JSONL file for training\n",
    "\n",
    "**File Paths:**\n",
    "- Input: `test_validated_NER_annotations.json` (Label Studio export)\n",
    "- Output: `gliner2_training_data.jsonl` (GLINER2 training format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b774f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Configuration loaded\n",
      "  Input:  C:\\Users\\vducatte\\OneDrive - UGent\\Documents\\BELHISFIRM\\NER\\gliner2-project\\test_validated_NER_annotations.json\n",
      "  Output: C:\\Users\\vducatte\\OneDrive - UGent\\Documents\\BELHISFIRM\\NER\\gliner2-project\\gliner2_training_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Set\n",
    "\n",
    "# File paths\n",
    "INPUT_FILE = r\"C:\\Users\\vducatte\\OneDrive - UGent\\Documents\\BELHISFIRM\\NER\\gliner2-project\\test_validated_NER_annotations.json\"\n",
    "OUTPUT_FILE = r\"C:\\Users\\vducatte\\OneDrive - UGent\\Documents\\BELHISFIRM\\NER\\gliner2-project\\gliner2_training_data.jsonl\"\n",
    "\n",
    "print(\"âœ“ Configuration loaded\")\n",
    "print(f\"  Input:  {INPUT_FILE}\")\n",
    "print(f\"  Output: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc6e2e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded 2 tasks from Label Studio export\n"
     ]
    }
   ],
   "source": [
    "def load_labelstudio_annotations(filepath: str) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Load Label Studio JSON export file.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to Label Studio JSON export\n",
    "        \n",
    "    Returns:\n",
    "        List of task dictionaries with annotations\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(f\"Expected a list of tasks, got {type(data)}\")\n",
    "    \n",
    "    print(f\"âœ“ Loaded {len(data)} tasks from Label Studio export\")\n",
    "    return data\n",
    "\n",
    "# Load the data\n",
    "tasks = load_labelstudio_annotations(INPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7374ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ Example from first document:\n",
      "  Text length: 2511 characters\n",
      "  Entity types found: 14\n",
      "  Entity types: ['ADDRESS', 'CITY', 'DATE', 'FILING_REFERENCE', 'GOVERNING_BODY', 'GPE', 'HONORIFIC', 'MANDATE', 'MEETING_SUBJECT', 'OCCUPATION', 'OFFICE_TYPE', 'ORGANIZATION', 'ORGANIZATION_TYPE', 'PERSON']\n",
      "\n",
      "  Sample entities:\n",
      "    DATE: ['neuf fÃ©vrier', 'vingt-six janvier dernier', 'mil neuf cent vingt-huit']\n",
      "    MEETING_SUBJECT: ['NOMINATIONS']\n",
      "    ORGANIZATION: ['SociÃ©tÃ© anonyme belge de la Manufacture de Bethune']\n"
     ]
    }
   ],
   "source": [
    "def extract_entities_from_labelstudio(task: dict) -> tuple[str, Dict[str, List[str]], Set[str]]:\n",
    "    \"\"\"\n",
    "    Extract entities from a Label Studio task.\n",
    "    \n",
    "    Args:\n",
    "        task: Label Studio task dictionary\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (text, entities_dict, entity_types_set)\n",
    "    \"\"\"\n",
    "    # Get the text\n",
    "    text = task.get('data', {}).get('text', '')\n",
    "    \n",
    "    if not text:\n",
    "        return None, {}, set()\n",
    "    \n",
    "    # Get annotations (prefer human annotations over predictions)\n",
    "    annotations_list = task.get('annotations', [])\n",
    "    \n",
    "    if not annotations_list:\n",
    "        # Fallback to predictions if no human annotations\n",
    "        predictions = task.get('predictions', [])\n",
    "        if predictions:\n",
    "            annotations_list = [predictions[0]]\n",
    "        else:\n",
    "            return text, {}, set()\n",
    "    \n",
    "    # Use the first annotation (or most recent)\n",
    "    annotation = annotations_list[0]\n",
    "    results = annotation.get('result', [])\n",
    "    \n",
    "    # Group entities by label\n",
    "    entities_by_label = defaultdict(list)\n",
    "    entity_types = set()\n",
    "    \n",
    "    for item in results:\n",
    "        # Only process label annotations (not relations)\n",
    "        if item.get('type') != 'labels':\n",
    "            continue\n",
    "        \n",
    "        value = item.get('value', {})\n",
    "        entity_text = value.get('text', '')\n",
    "        labels = value.get('labels', [])\n",
    "        \n",
    "        if not entity_text or not labels:\n",
    "            continue\n",
    "        \n",
    "        # Use the first label\n",
    "        label = labels[0]\n",
    "        entity_types.add(label)\n",
    "        \n",
    "        # Add entity mention\n",
    "        if entity_text not in entities_by_label[label]:\n",
    "            entities_by_label[label].append(entity_text)\n",
    "    \n",
    "    return text, dict(entities_by_label), entity_types\n",
    "\n",
    "# Test on first task\n",
    "if tasks:\n",
    "    text, entities, types = extract_entities_from_labelstudio(tasks[0])\n",
    "    print(\"\\nðŸ“ Example from first document:\")\n",
    "    print(f\"  Text length: {len(text)} characters\")\n",
    "    print(f\"  Entity types found: {len(types)}\")\n",
    "    print(f\"  Entity types: {sorted(types)}\")\n",
    "    print(f\"\\n  Sample entities:\")\n",
    "    for entity_type, mentions in list(entities.items())[:3]:\n",
    "        print(f\"    {entity_type}: {mentions[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ab1abb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‹ GLINER2 Example Format:\n",
      "{\n",
      "  \"input\": \"2134. - SociÃ©tÃ© anonyme belge de la Manufacture de Bethune, Ã  Bruxelles.\\n\\nNOMINATIONS.\\n\\nL'an mil neuf cent vingt-huit, le neuf fÃ©vrier.\\nEn notre etude a Bruxelles, rue du Moniteur, numÃ©ro 8.\\nDevant nous, Victor Scheyven, notaire rÃ©sidant Ã  Bruxelles.\\nS'est rÃ©unie, en application de l'article quarante des statuts, l'assemblÃ©e gÃ©nÃ©rale extraordinaire des associÃ©s de la sociÃ©tÃ© anonyme SociÃ©tÃ© anonyme belge de la Manufacture de Bethune, Ã©tablie Ã  BruxellÃ©s, constituÃ©e ce jour p...\n"
     ]
    }
   ],
   "source": [
    "def create_gliner2_example(text: str, entities: Dict[str, List[str]]) -> dict:\n",
    "    \"\"\"\n",
    "    Create a GLINER2 training example in the correct format.\n",
    "    \n",
    "    Args:\n",
    "        text: The input text\n",
    "        entities: Dictionary mapping entity types to lists of entity mentions\n",
    "        \n",
    "    Returns:\n",
    "        GLINER2 training example dictionary\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"input\": text,\n",
    "        \"output\": {\n",
    "            \"entities\": entities\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Test conversion\n",
    "if tasks:\n",
    "    text, entities, types = extract_entities_from_labelstudio(tasks[0])\n",
    "    example = create_gliner2_example(text, entities)\n",
    "    \n",
    "    print(\"\\nðŸ“‹ GLINER2 Example Format:\")\n",
    "    print(json.dumps(example, indent=2, ensure_ascii=False)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69a4c8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Conversion complete:\n",
      "  Total tasks: 2\n",
      "  Converted: 2\n",
      "  Skipped (no entities): 0\n"
     ]
    }
   ],
   "source": [
    "def convert_labelstudio_to_gliner2(tasks: List[dict]) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Convert all Label Studio tasks to GLINER2 format.\n",
    "    \n",
    "    Args:\n",
    "        tasks: List of Label Studio tasks\n",
    "        \n",
    "    Returns:\n",
    "        List of GLINER2 training examples\n",
    "    \"\"\"\n",
    "    gliner2_examples = []\n",
    "    skipped = 0\n",
    "    \n",
    "    for i, task in enumerate(tasks):\n",
    "        text, entities, types = extract_entities_from_labelstudio(task)\n",
    "        \n",
    "        # Skip if no text or no entities\n",
    "        if not text or not entities:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        \n",
    "        example = create_gliner2_example(text, entities)\n",
    "        gliner2_examples.append(example)\n",
    "    \n",
    "    print(f\"\\nâœ“ Conversion complete:\")\n",
    "    print(f\"  Total tasks: {len(tasks)}\")\n",
    "    print(f\"  Converted: {len(gliner2_examples)}\")\n",
    "    print(f\"  Skipped (no entities): {skipped}\")\n",
    "    \n",
    "    return gliner2_examples\n",
    "\n",
    "# Convert all tasks\n",
    "gliner2_data = convert_labelstudio_to_gliner2(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc34179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Saved 2 examples to: C:\\Users\\vducatte\\OneDrive - UGent\\Documents\\BELHISFIRM\\NER\\gliner2-project\\gliner2_training_data.jsonl\n",
      "  File size: 6,962 bytes (6.8 KB)\n"
     ]
    }
   ],
   "source": [
    "def save_gliner2_jsonl(examples: List[dict], filepath: str):\n",
    "    \"\"\"\n",
    "    Save GLINER2 examples to JSONL file.\n",
    "    Each line contains one JSON object (not a JSON array).\n",
    "    \n",
    "    Args:\n",
    "        examples: List of GLINER2 training examples\n",
    "        filepath: Output file path\n",
    "    \"\"\"\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        for example in examples:\n",
    "            json_line = json.dumps(example, ensure_ascii=False)\n",
    "            f.write(json_line + '\\n')\n",
    "    \n",
    "    print(f\"\\nâœ“ Saved {len(examples)} examples to: {filepath}\")\n",
    "    \n",
    "    # Show file size\n",
    "    import os\n",
    "    file_size = os.path.getsize(filepath)\n",
    "    print(f\"  File size: {file_size:,} bytes ({file_size/1024:.1f} KB)\")\n",
    "\n",
    "# Save to JSONL file\n",
    "save_gliner2_jsonl(gliner2_data, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3bc66c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ“Š DATASET STATISTICS\n",
      "============================================================\n",
      "\n",
      "Total examples: 2\n",
      "Total entity mentions: 84\n",
      "Unique entity types: 15\n",
      "\n",
      "Entity Type          Documents    Mentions   Avg/Doc\n",
      "------------------------------------------------------------\n",
      "ADDRESS              2            12         6.0\n",
      "CITY                 2            13         6.5\n",
      "DATE                 2            8          4.0\n",
      "FILING_REFERENCE     2            2          1.0\n",
      "GOVERNING_BODY       1            2          2.0\n",
      "GPE                  1            1          1.0\n",
      "HONORIFIC            2            3          1.5\n",
      "MANDATE              2            3          1.5\n",
      "MEETING_SUBJECT      2            2          1.0\n",
      "OCCUPATION           2            10         5.0\n",
      "OFFICE_TYPE          1            1          1.0\n",
      "ORGANIZATION         2            4          2.0\n",
      "ORGANIZATION_ACTIVITY 1            1          1.0\n",
      "ORGANIZATION_TYPE    2            4          2.0\n",
      "PERSON               2            18         9.0\n"
     ]
    }
   ],
   "source": [
    "def show_statistics(examples: List[dict]):\n",
    "    \"\"\"\n",
    "    Display statistics about the converted data.\n",
    "    \"\"\"\n",
    "    # Count entity types across all examples\n",
    "    from collections import Counter\n",
    "    \n",
    "    entity_type_counts = Counter()\n",
    "    entity_mention_counts = Counter()\n",
    "    total_mentions = 0\n",
    "    \n",
    "    for example in examples:\n",
    "        entities = example['output']['entities']\n",
    "        for entity_type, mentions in entities.items():\n",
    "            entity_type_counts[entity_type] += 1\n",
    "            entity_mention_counts[entity_type] += len(mentions)\n",
    "            total_mentions += len(mentions)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“Š DATASET STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nTotal examples: {len(examples)}\")\n",
    "    print(f\"Total entity mentions: {total_mentions}\")\n",
    "    print(f\"Unique entity types: {len(entity_type_counts)}\")\n",
    "    \n",
    "    print(f\"\\n{'Entity Type':<20} {'Documents':<12} {'Mentions':<10} {'Avg/Doc'}\")\n",
    "    print(\"-\" * 60)\n",
    "    for entity_type in sorted(entity_type_counts.keys()):\n",
    "        docs = entity_type_counts[entity_type]\n",
    "        mentions = entity_mention_counts[entity_type]\n",
    "        avg = mentions / docs\n",
    "        print(f\"{entity_type:<20} {docs:<12} {mentions:<10} {avg:.1f}\")\n",
    "\n",
    "# Show statistics\n",
    "show_statistics(gliner2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34799738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ” VALIDATION\n",
      "============================================================\n",
      "\n",
      "âœ“ File has 2 lines\n",
      "âœ“ All lines are valid JSON\n",
      "âœ“ All required fields present\n",
      "âœ“ Format is correct\n"
     ]
    }
   ],
   "source": [
    "def validate_gliner2_format(filepath: str) -> bool:\n",
    "    \"\"\"\n",
    "    Validate that the JSONL file has correct GLINER2 format.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to JSONL file\n",
    "        \n",
    "    Returns:\n",
    "        True if valid, False otherwise\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ” VALIDATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        print(f\"\\nâœ“ File has {len(lines)} lines\")\n",
    "        \n",
    "        # Check each line is valid JSON\n",
    "        errors = []\n",
    "        for i, line in enumerate(lines):\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                \n",
    "                # Check required fields\n",
    "                if 'input' not in data:\n",
    "                    errors.append(f\"Line {i+1}: Missing 'input' field\")\n",
    "                if 'output' not in data:\n",
    "                    errors.append(f\"Line {i+1}: Missing 'output' field\")\n",
    "                elif 'entities' not in data['output']:\n",
    "                    errors.append(f\"Line {i+1}: Missing 'entities' in output\")\n",
    "                \n",
    "                # Check entities is a dict\n",
    "                if 'output' in data and 'entities' in data['output']:\n",
    "                    if not isinstance(data['output']['entities'], dict):\n",
    "                        errors.append(f\"Line {i+1}: 'entities' must be a dict\")\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                errors.append(f\"Line {i+1}: Invalid JSON - {e}\")\n",
    "        \n",
    "        if errors:\n",
    "            print(f\"\\nâŒ Found {len(errors)} errors:\")\n",
    "            for error in errors[:10]:  # Show first 10 errors\n",
    "                print(f\"  â€¢ {error}\")\n",
    "            if len(errors) > 10:\n",
    "                print(f\"  ... and {len(errors) - 10} more\")\n",
    "            return False\n",
    "        else:\n",
    "            print(\"âœ“ All lines are valid JSON\")\n",
    "            print(\"âœ“ All required fields present\")\n",
    "            print(\"âœ“ Format is correct\")\n",
    "            return True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Validation failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Validate the output file\n",
    "is_valid = validate_gliner2_format(OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d94b06e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ” DETAILED EXAMPLE STRUCTURE\n",
      "============================================================\n",
      "\n",
      "ðŸ“¥ INPUT (first 300 characters):\n",
      "------------------------------------------------------------\n",
      "2134. - SociÃ©tÃ© anonyme belge de la Manufacture de Bethune, Ã  Bruxelles.\n",
      "\n",
      "NOMINATIONS.\n",
      "\n",
      "L'an mil neuf cent vingt-huit, le neuf fÃ©vrier.\n",
      "En notre etude a Bruxelles, rue du Moniteur, numÃ©ro 8.\n",
      "Devant nous, Victor Scheyven, notaire rÃ©sidant Ã  Bruxelles.\n",
      "S'est rÃ©unie, en application de l'article quarant...\n",
      "\n",
      "\n",
      "ðŸ“¤ OUTPUT (entities):\n",
      "------------------------------------------------------------\n",
      "Total entity types: 14\n",
      "\n",
      "  ADDRESS:\n",
      "    - \"rue du Faubourg d'Arras\"\n",
      "    - \"place du PanthÃ©on, numÃ©ro 1\"\n",
      "    - \"Grand'-\n",
      "Place, numÃ©ro 50\"\n",
      "    - \"Route Nationale\"\n",
      "    - \"rue du Moniteur, numÃ©ro 8\"\n",
      "\n",
      "  CITY:\n",
      "    - \"Bruxelles\"\n",
      "    - \"Paris\"\n",
      "    - \"NÅ“ux-les-Mines\"\n",
      "    - \"Arras\"\n",
      "    - \"Bethune\"\n",
      "    ... and 1 more\n",
      "\n",
      "  DATE:\n",
      "    - \"neuf fÃ©vrier\"\n",
      "    - \"vingt-six janvier dernier\"\n",
      "    - \"mil neuf cent vingt-huit\"\n",
      "    - \"vingt-sept janvier dernier\"\n",
      "\n",
      "  FILING_REFERENCE:\n",
      "    - \"2134\"\n",
      "\n",
      "  GOVERNING_BODY:\n",
      "    - \"conseil d'administration\"\n",
      "    - \"assemblÃ©e gÃ©nÃ©rale\"\n",
      "\n",
      "  GPE:\n",
      "    - \"France\"\n",
      "\n",
      "  HONORIFIC:\n",
      "    - \"M.\"\n",
      "    - \"Outrebon\"\n",
      "\n",
      "  MANDATE:\n",
      "    - \"administrateur dÃ©lÃ©guÃ©\"\n",
      "    - \"dÃ©lÃ©gation spÃ©ciale\"\n",
      "\n",
      "  MEETING_SUBJECT:\n",
      "    - \"NOMINATIONS\"\n",
      "\n",
      "  OCCUPATION:\n",
      "    - \"industriel\"\n",
      "    - \"brasseur\"\n",
      "    - \"notaire\"\n",
      "\n",
      "  OFFICE_TYPE:\n",
      "    - \"siÃ¨ge social\"\n",
      "\n",
      "  ORGANIZATION:\n",
      "    - \"SociÃ©tÃ© anonyme belge de la Manufacture de Bethune\"\n",
      "\n",
      "  ORGANIZATION_TYPE:\n",
      "    - \"sociÃ©tÃ© anonyme\"\n",
      "    - \"SociÃ©tÃ© anonyme\"\n",
      "\n",
      "  PERSON:\n",
      "    - \"Victor Scheyven\"\n",
      "    - \"M. LÃ©on ClÃ©ment\"\n",
      "    - \"M. Paul Engrand\"\n",
      "    - \"M. Edouard Outrebon\"\n",
      "    - \"M. Pierre Outrebon\"\n",
      "    ... and 2 more\n",
      "\n",
      "\n",
      "âœ… Format confirmed: Each line has 'input' (text) and 'output' (entities)\n"
     ]
    }
   ],
   "source": [
    "# Detailed preview of a complete example\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ” DETAILED EXAMPLE STRUCTURE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "example = gliner2_data[0]\n",
    "\n",
    "print(\"\\nðŸ“¥ INPUT (first 300 characters):\")\n",
    "print(\"-\" * 60)\n",
    "print(example['input'][:300] + \"...\")\n",
    "\n",
    "print(\"\\n\\nðŸ“¤ OUTPUT (entities):\")\n",
    "print(\"-\" * 60)\n",
    "entities = example['output']['entities']\n",
    "print(f\"Total entity types: {len(entities)}\")\n",
    "print()\n",
    "\n",
    "for entity_type, mentions in sorted(entities.items()):\n",
    "    print(f\"  {entity_type}:\")\n",
    "    # Show first 5 mentions for each type\n",
    "    for mention in mentions[:5]:\n",
    "        print(f\"    - \\\"{mention}\\\"\")\n",
    "    if len(mentions) > 5:\n",
    "        print(f\"    ... and {len(mentions) - 5} more\")\n",
    "    print()\n",
    "\n",
    "print(\"\\nâœ… Format confirmed: Each line has 'input' (text) and 'output' (entities)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gliner-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
